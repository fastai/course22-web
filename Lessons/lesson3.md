---
title: "3: Neural net foundations"
---

::: {layout="[30,70]"}

![](../images/bear_sunnies2.png)

Today we'll be learning about the mathematical foundations of deep learning: *Stochastic gradient descent* (SGD), and the flexibility of linear functions layered with non-linear activation functions. We'll be focussing particularly on a popular combination called the *Rectified linear function* (ReLU).

:::

## Video

<iframe width="514" height="289" src="https://www.youtube-nocookie.com/embed/hBBOjCiFcuo?modestbranding=1" title="fast.ai lesson 3" frameborder="0" allow="accelerometer; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

This lesson is based partly on [chapter 4](https://github.com/fastai/fastbook/blob/master/04_mnist_basics.ipynb) of the [book](https://www.amazon.com/Deep-Learning-Coders-fastai-PyTorch/dp/1492045527).

## Resources

- Notebooks for this lesson:
  - [HuggingFace Spaces Pets repository](https://huggingface.co/spaces/jph00/pets/tree/main)
  - [Which image models are best?](https://www.kaggle.com/code/jhoward/which-image-models-are-best/)
  - [How does a neural net really work?](https://www.kaggle.com/code/jhoward/how-does-a-neural-net-really-work)
- Other resources for the lesson
  - Titanic spreadsheet: see the [course repository](https://github.com/fastai/course22)
  - Titanic data (training CSV) can be downloaded from [Kaggle](https://www.kaggle.com/competitions/titanic/)
- [Solutions ](https://forums.fast.ai/t/fastbook-chapter-4-questionnaire-solutions-wiki/67253) to chapter 4 questions from the book

## Links from the lesson

- [Know your pet](https://gettoknowyourpet.com/)
- ["Lesson 0"](https://www.youtube.com/watch?v=gGxe2mN3kAg)

